{
  "config": {
    "error": {
      "cannot_connect": "Can't reach OpenAI. Check network and try again.",
      "invalid_auth": "Invalid OpenAI API key.",
      "unknown": "Unexpected error."
    },
    "step": {
      "user": {
        "title": "Connect OpenAI (optional)",
        "description": "If you plan to use OpenAI, enter your **OpenAI API key** now (usually starts with `sk-...`). You can also leave this blank and finish setup the Ollama provider; you can add a key later in Options.",
        "data": {
          "api_key": "OpenAI API key (optional)"
        }
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "Invalid config entry provided. Got {config_entry}"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "prompt": "Instructions",
          "chat_model_provider": "Chat model provider",
          "ollama_chat_model": "Ollama chat model",
          "openai_chat_model": "OpenAI chat model",
          "chat_model_temperature": "Chat model temperature",
          "vlm_provider": "VLM provider",
          "ollama_vlm": "Ollama VLM",
          "openai_vlm": "OpenAI VLM",
          "vlm_temperature": "VLM temperature",
          "summarization_provider": "Summarization provider",
          "ollama_summarization_model": "Ollama summarization model",
          "openai_summarization_model": "OpenAI summarization model",
          "summarization_model_temperature": "Summarization model temperature",
          "embedding_provider": "Embedding provider",
          "ollama_embedding_model": "Ollama embedding model",
          "openai_embedding_model": "OpenAI embedding model",
          "llm_hass_api": "Control Home Assistant",
          "recommended": "Recommended model settings",
          "video_analyzer_mode": "Video analyzer mode"
        },
        "data_description": {
          "prompt": "Instruct how the LLM should respond. This can be a template."
        }
      }
    }
  }
}